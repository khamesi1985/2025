{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khamesi1985/2025/blob/main/Decision_Tree_with_Maunal_PSO_FS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4kGXNK91cC1",
        "outputId": "3b92a0f7-e416-4752-f978-cb31d375c6ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*** DECISION TREE (D.T) CLASSIFIER ***\n",
            "--- Train Data Evaluate via Cross Validation by D.T ---\n",
            "F1-Scores for Each Fold By D.T : [0.91566265 0.89156627 0.89156627 0.84444444]\n",
            "Mean F1-Score by D.T : 0.8858\n",
            "--- Test Data Evaluate by D.T ---\n",
            "Accuracy On Test Data by D.T = 0.9035\n",
            "Precision On Test Data by D.T = 0.8974\n",
            "Recall On Test Data by D.T = 0.8333\n",
            "F1-Score On Test Data by D.T = 0.8642\n",
            "TP On Test Data by D.T =  35\n",
            "TN On Test Data by D.T =  68\n",
            "FP On Test Data by D.T =  4\n",
            "FN On Test Data by D.T =  7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.91      0.94      0.93        72\n",
            "           M       0.90      0.83      0.86        42\n",
            "\n",
            "    accuracy                           0.90       114\n",
            "   macro avg       0.90      0.89      0.89       114\n",
            "weighted avg       0.90      0.90      0.90       114\n",
            "\n",
            "-------------------------------------------------------\n",
            "Iteration 1 | Best Score: 0.0971\n",
            "Iteration 2 | Best Score: 0.0971\n",
            "Iteration 3 | Best Score: 0.0971\n",
            "Iteration 4 | Best Score: 0.0768\n",
            "Iteration 5 | Best Score: 0.0768\n",
            "Iteration 6 | Best Score: 0.0768\n",
            "Iteration 7 | Best Score: 0.0768\n",
            "Iteration 8 | Best Score: 0.0768\n",
            "Iteration 9 | Best Score: 0.0768\n",
            "Iteration 10 | Best Score: 0.0768\n",
            "Iteration 11 | Best Score: 0.0768\n",
            "Iteration 12 | Best Score: 0.0768\n",
            "Iteration 13 | Best Score: 0.0768\n",
            "Iteration 14 | Best Score: 0.0768\n",
            "Iteration 15 | Best Score: 0.0661\n",
            "Iteration 16 | Best Score: 0.0661\n",
            "Iteration 17 | Best Score: 0.0661\n",
            "Iteration 18 | Best Score: 0.0661\n",
            "Iteration 19 | Best Score: 0.0661\n",
            "Iteration 20 | Best Score: 0.0661\n",
            "Iteration 21 | Best Score: 0.0661\n",
            "Iteration 22 | Best Score: 0.0661\n",
            "Iteration 23 | Best Score: 0.0661\n",
            "Iteration 24 | Best Score: 0.0661\n",
            "Iteration 25 | Best Score: 0.0561\n",
            "Iteration 26 | Best Score: 0.0561\n",
            "Iteration 27 | Best Score: 0.0561\n",
            "Iteration 28 | Best Score: 0.0561\n",
            "Iteration 29 | Best Score: 0.0561\n",
            "Iteration 30 | Best Score: 0.0561\n",
            "Iteration 31 | Best Score: 0.0561\n",
            "Iteration 32 | Best Score: 0.0561\n",
            "Iteration 33 | Best Score: 0.0561\n",
            "Iteration 34 | Best Score: 0.0561\n",
            "Iteration 35 | Best Score: 0.0561\n",
            "Iteration 36 | Best Score: 0.0561\n",
            "Iteration 37 | Best Score: 0.0561\n",
            "Iteration 38 | Best Score: 0.0561\n",
            "Iteration 39 | Best Score: 0.0561\n",
            "Iteration 40 | Best Score: 0.0561\n",
            "Iteration 41 | Best Score: 0.0561\n",
            "Iteration 42 | Best Score: 0.0561\n",
            "Iteration 43 | Best Score: 0.0561\n",
            "Iteration 44 | Best Score: 0.0561\n",
            "Iteration 45 | Best Score: 0.0561\n",
            "Iteration 46 | Best Score: 0.0561\n",
            "Iteration 47 | Best Score: 0.0561\n",
            "Iteration 48 | Best Score: 0.0561\n",
            "Iteration 49 | Best Score: 0.0561\n",
            "Iteration 50 | Best Score: 0.0561\n",
            "Iteration 51 | Best Score: 0.0561\n",
            "Iteration 52 | Best Score: 0.0561\n",
            "Iteration 53 | Best Score: 0.0561\n",
            "Iteration 54 | Best Score: 0.0449\n",
            "Iteration 55 | Best Score: 0.0449\n",
            "Iteration 56 | Best Score: 0.0449\n",
            "Iteration 57 | Best Score: 0.0449\n",
            "Iteration 58 | Best Score: 0.0449\n",
            "Iteration 59 | Best Score: 0.0449\n",
            "Iteration 60 | Best Score: 0.0449\n",
            "Iteration 61 | Best Score: 0.0449\n",
            "Iteration 62 | Best Score: 0.0449\n",
            "Iteration 63 | Best Score: 0.0449\n",
            "Iteration 64 | Best Score: 0.0449\n",
            "Iteration 65 | Best Score: 0.0449\n",
            "Iteration 66 | Best Score: 0.0416\n",
            "Iteration 67 | Best Score: 0.0416\n",
            "Iteration 68 | Best Score: 0.0416\n",
            "Iteration 69 | Best Score: 0.0416\n",
            "Iteration 70 | Best Score: 0.0416\n",
            "Iteration 71 | Best Score: 0.0416\n",
            "Iteration 72 | Best Score: 0.0416\n",
            "Iteration 73 | Best Score: 0.0416\n",
            "Iteration 74 | Best Score: 0.0416\n",
            "Iteration 75 | Best Score: 0.0416\n",
            "Iteration 76 | Best Score: 0.0416\n",
            "Iteration 77 | Best Score: 0.0416\n",
            "Iteration 78 | Best Score: 0.0416\n",
            "Iteration 79 | Best Score: 0.0416\n",
            "Iteration 80 | Best Score: 0.0416\n",
            "Iteration 81 | Best Score: 0.0416\n",
            "Iteration 82 | Best Score: 0.0416\n",
            "Iteration 83 | Best Score: 0.0416\n",
            "Iteration 84 | Best Score: 0.0416\n",
            "Iteration 85 | Best Score: 0.0416\n",
            "Iteration 86 | Best Score: 0.0416\n",
            "Iteration 87 | Best Score: 0.0416\n",
            "Iteration 88 | Best Score: 0.0416\n",
            "Iteration 89 | Best Score: 0.0416\n",
            "Iteration 90 | Best Score: 0.0416\n",
            "Iteration 91 | Best Score: 0.0416\n",
            "Iteration 92 | Best Score: 0.0416\n",
            "Iteration 93 | Best Score: 0.0416\n",
            "Iteration 94 | Best Score: 0.0416\n",
            "Iteration 95 | Best Score: 0.0416\n",
            "Iteration 96 | Best Score: 0.0416\n",
            "Iteration 97 | Best Score: 0.0416\n",
            "Iteration 98 | Best Score: 0.0416\n",
            "Iteration 99 | Best Score: 0.0416\n",
            "Iteration 100 | Best Score: 0.0416\n",
            "\n",
            "Total Selected Features by P.S.O: 8/30\n",
            "\n",
            "Selected Features by P.S.O: [ 3  5  8  9 10 20 26 29]\n",
            "\n",
            "*** DECISION TREE (D.T) CLASSIFIER WITH P.S.O FEATURE SELECTION ***\n",
            "--- Train Data Evaluate via Cross Validation by D.T with P.S.O ---\n",
            "F1-Scores for Each Fold By D.T with P.S.O : [0.90909091 0.91358025 0.875      0.84337349]\n",
            "Mean F1-Score by D.T with P.S.O : 0.8853\n",
            "--- Test Data Evaluate by D.T with P.S.O ---\n",
            "Accuracy On Test Data by D.T with P.S.O = 0.9211\n",
            "Precision On Test Data by D.T with P.S.O = 0.9024\n",
            "Recall On Test Data by D.T with P.S.O = 0.8810\n",
            "F1-Score On Test Data by D.T with P.S.O = 0.8916\n",
            "TP On Test Data by D.T with P.S.O =  37\n",
            "TN On Test Data by D.T with P.S.O =  68\n",
            "FP On Test Data by D.T with P.S.O =  4\n",
            "FN On Test Data by D.T with P.S.O =  5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.93      0.94      0.94        72\n",
            "           M       0.90      0.88      0.89        42\n",
            "\n",
            "    accuracy                           0.92       114\n",
            "   macro avg       0.92      0.91      0.91       114\n",
            "weighted avg       0.92      0.92      0.92       114\n",
            "\n",
            "-------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "url = \"https://raw.githubusercontent.com/khamesi1985/2025/main/wdbc.data\"\n",
        "data = pd.read_csv(url, header=None)\n",
        "data = data.dropna()\n",
        "X_full = data.iloc[:, 2:32]\n",
        "Pre_Y = data.iloc[:, 1]\n",
        "make_bin = LabelEncoder()\n",
        "make_bin.fit(Pre_Y)\n",
        "Y_full = make_bin.transform(Pre_Y)\n",
        "\n",
        "#  تقسیم کل داده ها به دو قسمت آموزش و آزمون\n",
        "X_train_and_val, X_test, Y_train_and_val, Y_test = train_test_split(X_full, Y_full, test_size=0.2, random_state=42, stratify=Y_full)\n",
        "\n",
        "# استاندارد سازی داده ها\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train_and_val)\n",
        "X_train_and_val_scaled = scaler.transform(X_train_and_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "#  تقسیم داده‌های آموزش به دو قسمت آموزش و اعتبارسنجی\n",
        "X_train_scaled, X_val_scaled, Y_train, Y_val = train_test_split(X_train_and_val_scaled, Y_train_and_val, test_size=0.2, random_state=42, stratify=Y_train_and_val)\n",
        "\n",
        "# پیاده سازی مدل درخت تصمیم\n",
        "DT_model = DecisionTreeClassifier(random_state=42, class_weight='balanced')\n",
        "DT_scores = cross_val_score(DT_model, X_train_and_val_scaled, Y_train_and_val, cv=4, scoring='f1')\n",
        "DT_model.fit(X_train_and_val_scaled, Y_train_and_val)\n",
        "Y_pred_test_DT = DT_model.predict(X_test_scaled)\n",
        "\n",
        "# محاسبه دقت مدل درخت تصمیم\n",
        "accuracy_test_DT = accuracy_score(Y_test, Y_pred_test_DT)\n",
        "precision_test_DT = precision_score(Y_test, Y_pred_test_DT)\n",
        "recall_test_DT = recall_score(Y_test, Y_pred_test_DT)\n",
        "f1_score_test_DT = f1_score(Y_test, Y_pred_test_DT)\n",
        "print(\"\\n*** DECISION TREE (D.T) CLASSIFIER ***\")\n",
        "print(\"--- Train Data Evaluate via Cross Validation by D.T ---\")\n",
        "print(f\"F1-Scores for Each Fold By D.T : {DT_scores}\")\n",
        "print(f\"Mean F1-Score by D.T : {np.mean(DT_scores):.4f}\")\n",
        "print(\"--- Test Data Evaluate by D.T ---\")\n",
        "print(f\"Accuracy On Test Data by D.T = {accuracy_test_DT:.4f}\")\n",
        "print(f\"Precision On Test Data by D.T = {precision_test_DT:.4f}\")\n",
        "print(f\"Recall On Test Data by D.T = {recall_test_DT:.4f}\")\n",
        "print(f\"F1-Score On Test Data by D.T = {f1_score_test_DT:.4f}\")\n",
        "len_test = len(Y_test)\n",
        "TN = TP = FN = FP = 0\n",
        "for i in range (len_test):\n",
        "  if Y_test[i] == 0 and Y_pred_test_DT[i] == 1:\n",
        "    FP = FP + 1\n",
        "  elif Y_test[i] == 1 and Y_pred_test_DT[i] == 0:\n",
        "    FN = FN + 1\n",
        "  elif Y_test[i] == 1 and Y_pred_test_DT[i] == 1:\n",
        "    TP = TP + 1\n",
        "  elif Y_test[i] == 0 and Y_pred_test_DT[i] == 0:\n",
        "    TN = TN + 1\n",
        "print(\"TP On Test Data by D.T = \", TP)\n",
        "print(\"TN On Test Data by D.T = \", TN)\n",
        "print(\"FP On Test Data by D.T = \", FP)\n",
        "print(\"FN On Test Data by D.T = \", FN)\n",
        "print(classification_report(Y_test, Y_pred_test_DT, target_names=make_bin.classes_))\n",
        "print(\"-\"*55)\n",
        "\n",
        "# پیاده سازی الگوریتم بهینه سازی گروه ذرات و انتخاب بهترین ویژگی ها\n",
        "particles = 20\n",
        "iterations = 100\n",
        "dimensions = X_train_scaled.shape[1]\n",
        "c1 = 1\n",
        "c2 = 2\n",
        "w = 0.9\n",
        "alfa = 0.1\n",
        "np.random.seed(12)\n",
        "positions = np.random.uniform(0, 1, (particles, dimensions))\n",
        "velocities = np.zeros((particles, dimensions))\n",
        "personal_best_positions = positions.copy()\n",
        "personal_best_scores = np.ones(particles) * np.inf\n",
        "global_best_score = np.inf\n",
        "global_best_position = positions[0].copy()\n",
        "for iteration in range(iterations):\n",
        "  for i in range(particles):\n",
        "    r1 = np.random.rand(dimensions)\n",
        "    r2 = np.random.rand(dimensions)\n",
        "    velocities[i] = (w * velocities[i] + c1 * r1 * (personal_best_positions[i] - positions[i]) + c2 * r2 * (global_best_position - positions[i]))\n",
        "    positions[i] = positions[i] + velocities[i]\n",
        "    # محاسبه برازندگی ذره جدید\n",
        "    subset_features = (positions[i] > 0.5)\n",
        "    if np.sum(subset_features) == 0:\n",
        "      score = 1.0\n",
        "    else:\n",
        "      X_train_selected = X_train_scaled[:, subset_features]\n",
        "      X_val_selected = X_val_scaled[:, subset_features]\n",
        "      model = DecisionTreeClassifier(random_state=42, class_weight='balanced')\n",
        "      model.fit(X_train_selected, Y_train)\n",
        "      Y_pred_val = model.predict(X_val_selected)\n",
        "      f1 = f1_score(Y_val, Y_pred_val)\n",
        "      penalty = alfa * (np.sum(subset_features) / dimensions)\n",
        "      score = 1 - f1 + penalty\n",
        "    # به‌روزرسانی بهترین وضعیت شخصی\n",
        "    if score < personal_best_scores[i]:\n",
        "      personal_best_positions[i] = positions[i].copy()\n",
        "      personal_best_scores[i] = score\n",
        "  # به‌روزرسانی بهترین وضعیت کلی\n",
        "  best_index = np.argmin(personal_best_scores)\n",
        "  if personal_best_scores[best_index] < global_best_score:\n",
        "    global_best_position = personal_best_positions[best_index].copy()\n",
        "    global_best_score = personal_best_scores[best_index]\n",
        "  print(f\"Iteration {iteration+1} | Best Score: {global_best_score:.4f}\")\n",
        "# انتخاب نهایی ویژگی‌ها بر اساس بهترین موقعیت کلی\n",
        "best_features_mask = (global_best_position > 0.5)\n",
        "num_selected_features = np.sum(best_features_mask)\n",
        "print(f\"\\nTotal Selected Features by P.S.O: {num_selected_features}/{dimensions}\")\n",
        "selected_features = np.where(best_features_mask == 1)[0]\n",
        "print(f\"\\nSelected Features by P.S.O: {selected_features}\")\n",
        "X_train_selected_final = X_train_and_val_scaled[:, best_features_mask]\n",
        "X_test_selected = X_test_scaled[:, best_features_mask]\n",
        "\n",
        "# پیاده سازی مدل درخت تصمیم بعد از انتخاب ویژگی های بهینه توسط الگوریتم بهینه سازی گروه ذرات P.S.O\n",
        "DT_model_with_PSO = DecisionTreeClassifier(random_state=42, class_weight='balanced')\n",
        "DT_scores_with_PSO = cross_val_score(DT_model_with_PSO, X_train_selected_final, Y_train_and_val, cv=4, scoring='f1')\n",
        "DT_model_with_PSO.fit(X_train_selected_final, Y_train_and_val)\n",
        "Y_pred_test_DT_with_PSO = DT_model_with_PSO.predict(X_test_selected)\n",
        "\n",
        "# محاسبه دقت مدل درخت تصمیم بعد از انتخاب ویژگی های بهینه توسط الگوریتم بهینه سازی گروه ذرات P.S.O\n",
        "accuracy_test_DT_with_PSO = accuracy_score(Y_test, Y_pred_test_DT_with_PSO)\n",
        "precision_test_DT_with_PSO = precision_score(Y_test, Y_pred_test_DT_with_PSO)\n",
        "recall_test_DT_with_PSO = recall_score(Y_test, Y_pred_test_DT_with_PSO)\n",
        "f1_score_test_DT_with_PSO = f1_score(Y_test, Y_pred_test_DT_with_PSO)\n",
        "print(\"\\n*** DECISION TREE (D.T) CLASSIFIER WITH P.S.O FEATURE SELECTION ***\")\n",
        "print(\"--- Train Data Evaluate via Cross Validation by D.T with P.S.O ---\")\n",
        "print(f\"F1-Scores for Each Fold By D.T with P.S.O : {DT_scores_with_PSO}\")\n",
        "print(f\"Mean F1-Score by D.T with P.S.O : {np.mean(DT_scores_with_PSO):.4f}\")\n",
        "print(\"--- Test Data Evaluate by D.T with P.S.O ---\")\n",
        "print(f\"Accuracy On Test Data by D.T with P.S.O = {accuracy_test_DT_with_PSO:.4f}\")\n",
        "print(f\"Precision On Test Data by D.T with P.S.O = {precision_test_DT_with_PSO:.4f}\")\n",
        "print(f\"Recall On Test Data by D.T with P.S.O = {recall_test_DT_with_PSO:.4f}\")\n",
        "print(f\"F1-Score On Test Data by D.T with P.S.O = {f1_score_test_DT_with_PSO:.4f}\")\n",
        "len_test = len(Y_test)\n",
        "TN = TP = FN = FP = 0\n",
        "for i in range (len_test):\n",
        "  if Y_test[i] == 0 and Y_pred_test_DT_with_PSO[i] == 1:\n",
        "    FP = FP + 1\n",
        "  elif Y_test[i] == 1 and Y_pred_test_DT_with_PSO[i] == 0:\n",
        "    FN = FN + 1\n",
        "  elif Y_test[i] == 1 and Y_pred_test_DT_with_PSO[i] == 1:\n",
        "    TP = TP + 1\n",
        "  elif Y_test[i] == 0 and Y_pred_test_DT_with_PSO[i] == 0:\n",
        "    TN = TN + 1\n",
        "print(\"TP On Test Data by D.T with P.S.O = \", TP)\n",
        "print(\"TN On Test Data by D.T with P.S.O = \", TN)\n",
        "print(\"FP On Test Data by D.T with P.S.O = \", FP)\n",
        "print(\"FN On Test Data by D.T with P.S.O = \", FN)\n",
        "print(classification_report(Y_test, Y_pred_test_DT_with_PSO, target_names=make_bin.classes_))\n",
        "print(\"-\"*55)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMv/BDDlNuKBVnI780FRPfu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}